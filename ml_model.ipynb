{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import sqlite3 as sql3\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "import keras_tuner as kt\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data from sqlite file\n",
    "database_path = './FlaskSQLBackend/laptop_data_database.sqlite'\n",
    "\n",
    "laptop_df = ''\n",
    "\n",
    "with sql3.connect(database_path) as conn:\n",
    "    laptop_df = pd.read_sql(\"SELECT * FROM Laptops\", conn)\n",
    "\n",
    "    laptop_df = pd.get_dummies(laptop_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "print(len(laptop_df.columns))\n",
    "\n",
    "X = laptop_df.drop('PRICE', axis=1)  # Assuming 'PRICE' is the target variable\n",
    "y = laptop_df['PRICE']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # Adjust test size as needed\n",
    "\n",
    "# Scale numerical features using StandardScaler\n",
    "numerical_features = ['INCHES', 'MEMORY', 'WEIGHT', 'SCREENWIDTH', 'SCREENHEIGHT', 'CPUSPEED', 'PRIMARYSTORAGEAMOUNT', 'SECONDARYSTORAGEAMOUNT']\n",
    "X[numerical_features].apply(pd.to_numeric)\n",
    "X = X.dropna(how='any',axis=0) \n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "X_train[numerical_features] = X_scaler.fit_transform(X_train[numerical_features])\n",
    "X_test[numerical_features] = X_scaler.transform(X_test[numerical_features]) # Use the same scaler fitted on training data\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_train = y_scaler.fit_transform(pd.DataFrame(y_train))\n",
    "y_test = y_scaler.transform(pd.DataFrame(y_test)) # Use the same scaler fitted on training data\n",
    "\n",
    "X_train = X_train.to_numpy().astype(np.float32)\n",
    "X_test = X_test.to_numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 29 Complete [00h 00m 05s]\n",
      "val_loss: 0.2731573283672333\n",
      "\n",
      "Best val_loss So Far: 0.14346586167812347\n",
      "Total elapsed time: 00h 01m 12s\n",
      "\n",
      "Search: Running Trial #30\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "relu              |relu              |activation\n",
      "56                |50                |first_units\n",
      "1                 |2                 |num_layers\n",
      "46                |32                |units_0\n",
      "62                |46                |units_1\n",
      "52                |76                |units_2\n",
      "12                |46                |units_3\n",
      "76                |50                |units_4\n",
      "20                |20                |tuner/epochs\n",
      "0                 |7                 |tuner/initial_epoch\n",
      "0                 |2                 |tuner/bracket\n",
      "0                 |2                 |tuner/round\n",
      "\n",
      "Epoch 1/20\n",
      "33/33 [==============================] - 1s 10ms/step - loss: 0.6209 - mae: 0.5622 - val_loss: 0.3651 - val_mae: 0.4109\n",
      "Epoch 2/20\n",
      " 4/33 [==>...........................] - ETA: 0s - loss: 0.3409 - mae: 0.3957"
     ]
    }
   ],
   "source": [
    "def create_model(hp):\n",
    "\t# Creating the model\n",
    "\tnn_model = tf.keras.models.Sequential()\n",
    "\n",
    "\t# Allowing the kerastuner to decide which activation function to use in the hidden layers\n",
    "\tactivation = hp.Choice('activation', ['relu', 'tanh', 'sigmoid'])\n",
    "\n",
    "\tnn_model.add(tf.keras.layers.Dense(\n",
    "\t\tunits = hp.Int(\n",
    "\t\t\t'first_units',\n",
    "\t\t\tmin_value=30,\n",
    "\t\t\tmax_value=90,\n",
    "\t\t\tstep=2\n",
    "\t\t),\n",
    "\t\tactivation = activation,\n",
    "\t\tinput_dim=62\n",
    "\t))\n",
    "\n",
    "\tfor i in range(hp.Int('num_layers', 1, 5)):\n",
    "\t\tnn_model.add(tf.keras.layers.Dense(\n",
    "\t\t\tunits = hp.Int(\n",
    "\t\t\t\t'units_' + str(i),\n",
    "\t\t\t\tmin_value=10,\n",
    "\t\t\t\tmax_value=80,\n",
    "\t\t\t\tstep=2\n",
    "\t\t\t),\n",
    "\t\t\tactivation = activation\n",
    "\t\t))\n",
    "\n",
    "\tnn_model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "\tnn_model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "\treturn nn_model\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "\tcreate_model,\n",
    "\tobjective='val_loss', # Validation accuracy\n",
    "\tmax_epochs=80,\n",
    "\thyperband_iterations=2\n",
    ")\n",
    "\n",
    "# Tuning for the best hyperparameters\n",
    "tuner.search(X_train, y_train, epochs=80, validation_data=(X_test, y_test))\n",
    "\n",
    "best_hyper = tuner.get_best_hyperparameters(1)[0]\n",
    "\n",
    "nn_model = tuner.get_best_models(1)[0]\n",
    "\n",
    "#nn_model = tf.keras.Sequential([\n",
    "#    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)), # Input layer with correct shape\n",
    "#    tf.keras.layers.Dense(32, activation='relu'),\n",
    "#    tf.keras.layers.Dense(16, activation='relu'),\n",
    "#    tf.keras.layers.Dense(1) # Output layer with a single neuron for regression (price)\n",
    "#])\n",
    "# fit_model = nn_model.fit(X_train, y_train, epochs=65, batch_size=32)\n",
    "\n",
    "nn_model.summary()\n",
    "\n",
    "nn_model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n",
      "Loss: 0.12896502017974854\n",
      "Mean Absolute Error: 0.2421550750732422\n",
      "R Squared: 0.8758468132250212\n",
      "        Predicted       Actual\n",
      "0    29955.500000   35964.0000\n",
      "1    68258.539062   71847.0144\n",
      "2   128591.601562  111834.7200\n",
      "3    98449.679688  101178.7200\n",
      "4    29191.908203   24455.5200\n",
      "5    69504.656250   74538.1872\n",
      "6   100266.007812   95850.7200\n",
      "7    89072.046875   79866.7200\n",
      "8    77663.296875   86793.1200\n",
      "9    17280.847656   18594.7200\n",
      "10   16292.695312   12201.1200\n",
      "11   92390.257812  107257.9680\n",
      "12   52670.226562   67772.1600\n",
      "13   51656.175781   66546.7200\n",
      "14   96672.070312   94731.8400\n",
      "15   31357.068359   36089.2080\n",
      "16   31219.378906   24935.0400\n",
      "17   29280.535156   32713.9200\n",
      "18   86681.656250   95850.7200\n",
      "19   34772.695312   63882.7200\n",
      "20   38550.878906   51095.5200\n",
      "21   65469.460938   55922.6880\n",
      "22   31583.355469   37570.3920\n",
      "23   44060.027344   35111.5200\n",
      "24   44340.601562   53733.9456\n",
      "25   52801.035156   53226.7200\n",
      "26  120324.117188   93932.6400\n",
      "27   46552.417969   61485.1200\n",
      "28   24723.519531   32767.2000\n",
      "29  130737.554688   67612.3200\n",
      "30   29191.906250   24455.5200\n",
      "31  277945.156250  324954.7200\n",
      "32   26666.050781   22857.1200\n",
      "33   77792.320312   92121.1200\n",
      "34   63054.843750   58554.7200\n",
      "35   21908.992188   18434.3472\n",
      "36   68044.625000   40066.5600\n",
      "37   80845.539062   65480.5872\n",
      "38   96242.773438  108744.4800\n",
      "39   21374.269531   23655.7872\n",
      "40   52535.855469   67026.2400\n",
      "41   30200.785156   27652.3200\n",
      "42   26274.320312   26586.7200\n",
      "43   31868.273438   46300.3200\n",
      "44  150572.640625  154458.7200\n",
      "45   67473.859375   47898.7200\n",
      "46   99455.343750  105654.2400\n",
      "47   26096.949219   28238.4000\n",
      "48   27936.404297   41345.2800\n",
      "49   78456.171875   95850.7200\n"
     ]
    }
   ],
   "source": [
    "loss, mae = nn_model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "predicted_y = [x[0] for x in y_scaler.inverse_transform(nn_model.predict(X_test))]\n",
    "y_test = [x[0] for x in y_scaler.inverse_transform(y_test)]\n",
    "r_square = r2_score(y_test, predicted_y)\n",
    "\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"R Squared: {r_square}\")\n",
    "\n",
    "\n",
    "dataframe_values = pd.DataFrame({\n",
    "    \"Predicted\" : predicted_y,\n",
    "    \"Actual\" : y_test\n",
    "})\n",
    "\n",
    "print(dataframe_values.head(50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
